<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <title>Machine Learning</title>
        <link rel="icon" href="..//images/machine learning logo.png">
    </head>
    <style>

        body {
          background-color: #faf2e4;
          margin: 0 15%;
          font-family: sans-serif;
          }
        
        h1 {
          text-align: center;
          font-family: serif;
          font-weight: normal;
          text-transform: uppercase;
          border-bottom: 1px solid #57b1dc;
          margin-top: 30px;
        }
        
        h2 {
          color: #d1633c;
          font-size: 1em;
        }
        marquee{
      font-size: 30px;
      font-weight: 800;
      color: #8ebf42;
      font-family: sans-serif;
      }
      a:link {
  color: green;
  background-color: transparent;
  text-decoration: none;
}

a:visited {
  color: rgb(0, 0, 0);
  background-color: transparent;
  text-decoration: none;
}

a:hover {
  color: rgb(0, 119, 255);
  background-color: transparent;
  text-decoration: underline;
}

a:active {
  color: rgb(255, 0, 0);
  background-color: transparent;
  text-decoration: underline;
}
        
        </style>
    <body>
        <table >

        <tr>
            <td style="border:2px solid black; width:15%;"><a href="../main.html">Back to Home</a></td>
            <td style="border:2px solid black;" colspan="4" align="center">Machine Learning</td>
        </tr>
        <br><hr>

        <tr>
            <td colspan="5" style="border:2px solid black;"><p style="text-align: center;"><br><b>What is Machine Learning?</b><br></p>
              Machine learning is a branch of artificial intelligence (AI) and computer science which focuses on the use of data and algorithms to imitate the way that humans learn, gradually improving its accuracy.
              
              IBM has a rich history with machine learning. One of its own, Arthur Samuel, is credited for coining the term, “machine learning” with his research (PDF, 481 KB) (link resides outside IBM) around the game of checkers. Robert Nealey, the self-proclaimed checkers master, played the game on an IBM 7094 computer in 1962, and he lost to the computer. Compared to what can be done today, this feat almost seems trivial, but it’s considered a major milestone within the field of artificial intelligence. Over the next couple of decades, the technological developments around storage and processing power will enable some innovative products that we know and love today, such as Netflix’s recommendation engine or self-driving cars.
              
              Machine learning is an important component of the growing field of data science. Through the use of statistical methods, algorithms are trained to make classifications or predictions, uncovering key insights within data mining projects. These insights subsequently drive decision making within applications and businesses, ideally impacting key growth metrics. As big data continues to expand and grow, the market demand for data scientists will increase, requiring them to assist in the identification of the most relevant business questions and subsequently the data to answer them.
              <p style="text-align: center;"><br><b>Machine Learning vs. Deep Learning vs. Neural Networks</b><br></p>
Since deep learning and machine learning tend to be used interchangeably, it’s worth noting the nuances between the two. Machine learning, deep learning, and neural networks are all sub-fields of artificial intelligence. However, deep learning is actually a sub-field of machine learning, and neural networks is a sub-field of deep learning.

The way in which deep learning and machine learning differ is in how each algorithm learns. Deep learning automates much of the feature extraction piece of the process, eliminating some of the manual human intervention required and enabling the use of larger data sets. You can think of deep learning as "scalable machine learning" as Lex Fridman notes in this MIT lecture (00:30) (link resides outside IBM). Classical, or "non-deep", machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn.

"Deep" machine learning can leverage labeled datasets, also known as supervised learning, to inform its algorithm, but it doesn’t necessarily require a labeled dataset. It can ingest unstructured data in its raw form (e.g. text, images), and it can automatically determine the set of features which distinguish different categories of data from one another. Unlike machine learning, it doesn't require human intervention to process data, allowing us to scale machine learning in more interesting ways. Deep learning and neural networks are primarily credited with accelerating progress in areas, such as computer vision, natural language processing, and speech recognition.

Neural networks, or artificial neural networks (ANNs), are comprised of a node layers, containing an input layer, one or more hidden layers, and an output layer. Each node, or artificial neuron, connects to another and has an associated weight and threshold. If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network. Otherwise, no data is passed along to the next layer of the network. The “deep” in deep learning is just referring to the depth of layers in a neural network. A neural network that consists of more than three layers—which would be inclusive of the inputs and the output—can be considered a deep learning algorithm or a deep neural network. A neural network that only has two or three layers is just a basic neural network.
<p style="text-align: center;"><br><b>How Machine Learning Works</b><br></p>
UC Berkeley (link resides outside IBM) breaks out the learning system of a machine learning algorithm into three main parts.

A Decision Process: In general, machine learning algorithms are used to make a prediction or classification. Based on some input data, which can be labelled or unlabeled, your algorithm will produce an estimate about a pattern in the data.
An Error Function: An error function serves to evaluate the prediction of the model. If there are known examples, an error function can make a comparison to assess the accuracy of the model.
An Model Optimization Process: If the model can fit better to the data points in the training set, then weights are adjusted to reduce the discrepancy between the known example and the model estimate. The algorithm will repeat this evaluate and optimize process, updating weights autonomously until a threshold of accuracy has been met.  



              
            </td>
        </tr>
        </table>
        <marquee>A new machine-learning system costs less, generates less waste, and can be more innovative than manual discovery methods.</marquee>
        <hr>
    </body>
</html>
